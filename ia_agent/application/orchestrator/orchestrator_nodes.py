"""
Nodos del grafo de orquestaci√≥n usando LangGraph.
Define el estado y las funciones de cada nodo del flujo.
"""
import json
from typing import TypedDict, Dict, Any
from sistemas.application.jira_service import JiraService
from ia_agent.application.orchestrator.redis_action_store import RedisActionStore
from ia_agent.application.orchestrator.intent_engine import IntentEngine
from ia_agent.application.orchestrator.action_loader import ActionFactory
import re


class OrchestratorState(TypedDict):
    """Estado compartido entre nodos del grafo"""
    user_message: str
    area: str
    username: str
    company: str  # Identificador de la compa√±√≠a/tenant
    tags: list  # Tags opcionales para filtrado adicional
    actions: Dict[str, Any]
    interpretation: Dict[str, Any]
    result: Dict[str, Any]
    preselect: Dict[str, Any]  # Metadatos de preselecci√≥n para routing

def _missing_required_for(action_name: str, params: Dict[str, Any], state: OrchestratorState) -> list:
    """Devuelve la lista de par√°metros requeridos que faltan para una acci√≥n."""
    cfg = state["actions"].get(action_name) or {}
    schema = cfg.get("parameters", {}) or {}
    required = schema.get("required", []) or []
    missing = [k for k in required if not params.get(k)]
    return missing


def should_execute_action(state: OrchestratorState) -> str:
    """
    Funci√≥n de routing condicional.
    Decide si ejecutar la acci√≥n o terminar el flujo basado en la interpretaci√≥n.
    
    Returns:
        'execute' si hay una acci√≥n v√°lida para ejecutar
        'end' si la interpretaci√≥n fall√≥ o no pudo determinar acci√≥n
    """
    interpretation = state.get("interpretation", {})
    action_name = interpretation.get("action")
    
    print(f"üîÄ Routing: action='{action_name}'")
    
    # Si no hay acci√≥n o es 'none', terminar directamente
    if not action_name or action_name == "none":
        # Preparar resultado de error antes de terminar
        error_msg = interpretation.get("_error")
        msg = "No se pudo determinar una acci√≥n clara."
        if error_msg:
            msg = f"No se pudo generar la respuesta: {error_msg}"
        
        state["result"] = {
            "status": False,
            "msg": msg,
            "data": {
                "opciones": list(state["actions"].keys())
            }
        }
        print(f"‚ùå Routing ‚Üí END (sin acci√≥n v√°lida)")
        return "end"
    
    # Si hay acci√≥n, continuar a ejecuci√≥n
    print(f"‚úÖ Routing ‚Üí EXECUTE (acci√≥n: {action_name})")
    return "execute"


def should_interpret_intent(state: OrchestratorState) -> str:
    """
    Funci√≥n de routing condicional despu√©s de get_actions.
    Decide si vale la pena llamar al LLM o terminar directamente.
    
    Returns:
        'interpret' si hay acciones disponibles para interpretar
        'end' si no hay acciones disponibles (ahorra tokens)
    """
    actions = state.get("actions", {})
    
    # Si no hay acciones disponibles, no tiene sentido usar el LLM
    if not actions or len(actions) == 0:
        state["result"] = {
            "status": False,
            "msg": "No se encontrado una accion concreta para tu consulta, puedes replantearla por favor.",
            "data": {
                "area": state.get("area"),
                "company": state.get("company"),
                "sugerencia": "Verifica que el √°rea sea correcta o que haya acciones configuradas."
            }
        }
        print(f"üö´ Sin acciones disponibles ‚Üí Saltando LLM (ahorro de tokens)")
        return "end"
    
    # Si hay acciones, continuar con interpretaci√≥n
    print(f"‚úÖ {len(actions)} acciones disponibles ‚Üí Llamando al LLM")
    return "interpret"


# ------------------------------------------------------------
# Preselecci√≥n ligera sin LLM (ahorro de tokens)
# ------------------------------------------------------------
# Umbrales de decisi√≥n para preselecci√≥n y uso de LLM
MIN_LLM_TRIGGER = 0.30  # si el mejor score es menor, no vale la pena llamar al LLM
MIN_LLM_MARGIN = 0.05   # si la diferencia entre top y segundo es menor, es ambiguo


def _normalize_text(text: str) -> str:
    text = (text or "").lower()
    return re.sub(r"[^a-z0-9√°√©√≠√≥√∫√±√º\s]", " ", text)


def _tokenize(text: str) -> set:
    return {t for t in _normalize_text(text).split() if t}


def _score_against_action(name: str, cfg: Dict[str, Any], query_tokens: set) -> float:
    parts = [name, cfg.get("description", "")]
    tags = cfg.get("tags", []) or cfg.get("keywords", []) or []
    if isinstance(tags, list):
        parts.extend(tags)
    elif isinstance(tags, str):
        parts.append(tags)
    text = " ".join(map(str, parts))
    tokens = _tokenize(text)
    if not tokens or not query_tokens:
        return 0.0
    overlap = len(tokens & query_tokens)
    score = overlap / (len(query_tokens) or 1)
    if name in tokens:
        score += 0.2
    if cfg.get("type") == "composite":
        score += 0.1
    return score


def preselect_intent(state: OrchestratorState) -> OrchestratorState:
    """
    Intent matching ligero y determin√≠stico sin LLM.
    Si existe un match fuerte y claro, fija la acci√≥n en el estado
    para evitar llamar al LLM.
    """
    message = state.get("user_message", "")
    actions = state.get("actions", {})
    user_tokens = _tokenize(message)
    # Incluir tags del request como se√±ales adicionales
    user_tokens |= {str(t).lower() for t in (state.get("tags") or [])}

    scored = []
    for name, cfg in actions.items():
        score = _score_against_action(name, cfg, user_tokens)
        scored.append((score, name))

    if not scored:
        state["interpretation"] = {"action": "none", "params": {}}
        print("ü§∑‚Äç‚ôÇÔ∏è Preselect: sin acciones para evaluar")
        return state

    scored.sort(key=lambda x: x[0], reverse=True)
    top = scored[0]
    second = scored[1] if len(scored) > 1 else (0.0, None)

    top_score, top_name = top
    second_score, _ = second

    print(f"üîé Preselect scores ‚Üí top: {top_name}={top_score:.2f}, second={second_score:.2f}")

    # Umbrales: requerimos confianza m√≠nima y separaci√≥n suficiente
    STRONG_MATCH = 0.55
    MARGIN = 0.20
    if top_score >= STRONG_MATCH and (top_score - second_score) >= MARGIN:
        state["interpretation"] = {"action": top_name, "params": {}}
        print(f"‚úÖ Preselect hit ‚Üí acci√≥n: {top_name}")
    else:
        state["interpretation"] = {"action": "none", "params": {}}
        print("ü§î Preselect inconcluso ‚Üí requerir√° LLM")

    # Guardar metadatos de preselect para routing posterior
    state["preselect"] = {
        "top_action": top_name,
        "top_score": top_score,
        "second_score": second_score
    }

    return state


def should_proceed_after_preselect(state: OrchestratorState) -> str:
    """
    Si la preselecci√≥n determin√≥ una acci√≥n v√°lida, ejecutar directo.
    De lo contrario, proceder a LLM para interpretaci√≥n.
    """
    action_name = (state.get("interpretation") or {}).get("action")
    if action_name and action_name != "none":
        print(f"üöÄ Saltando LLM: Ejecutando '{action_name}' por preselect")
        return "execute"

    # Si no hubo acci√≥n por preselect, decidir si vale la pena llamar al LLM
    ps = state.get("preselect", {}) or {}
    top = float(ps.get("top_score", 0.0))
    second = float(ps.get("second_score", 0.0))
    margin = top - second
    print(f"üßÆ Gate LLM: top={top:.2f}, margin={margin:.2f} (min_top={MIN_LLM_TRIGGER}, min_margin={MIN_LLM_MARGIN})")

    # Solo saltar el LLM si la confianza del mejor candidato es muy baja.
    # Si hay buenos candidatos pero est√°n empatados (ambig√ºedad), DEBEMOS llamar al LLM.
    if top < MIN_LLM_TRIGGER:
        state["result"] = {
            "status": False,
            "msg": "No se encontrado una accion concreta para tu consulta, puedes replantearla por favor.",
            "data": {
                "opciones": list(state.get("actions", {}).keys()),
                "sugerencia": "Intenta mencionar expl√≠citamente una de las acciones disponibles.",
                "top_sugerido": ps.get("top_action")
            }
        }
        print("üõë Gate LLM: saltando interpretaci√≥n por baja confianza/ambig√ºedad")
        return "end"

    # En caso contrario, vale la pena intentar con LLM
    return "interpret"



def get_actions(state: OrchestratorState) -> OrchestratorState:
    """
    Obtiene las acciones disponibles desde Redis.
    Filtra por compa√±√≠a y √°rea para soporte multi-tenant.
    
    Args:
        state: Estado actual del orquestador
        
    Returns:
        Estado actualizado con las acciones
    """
    company = state.get("company", "default")
    area = state.get("area", "")
    
    # Siempre cargar acciones default (base para todos)
    default_actions = RedisActionStore.get_all(key="actions:default")
    
    # Si la empresa es diferente de default, cargar sus acciones espec√≠ficas
    if company != "default":
        company_actions = RedisActionStore.get_all(key=f"actions:{company}")
        all_actions = {**default_actions, **company_actions}
    else:
        all_actions = default_actions

    # Filtrar por √°rea: mantener acciones sin √°rea definida (globales) y las del √°rea espec√≠fica
    def area_matches(cfg: Dict[str, Any]) -> bool:
        action_area = cfg.get("area")
        return (action_area is None) or (action_area == "global") or (str(action_area).lower() == str(area).lower())
    
    # Filtrar por tags: si el mensaje o los tags del request contienen keywords de los tags de la acci√≥n
    def has_relevant_tags(cfg: Dict[str, Any]) -> bool:
        action_tags = cfg.get("tags", []) or cfg.get("keywords", []) or []
        if not action_tags:
            return True  # Sin tags = pasa el filtro (neutro)
        
        # Obtener tags del usuario (si los envi√≥) y mensaje
        user_tags = [t.lower() for t in (state.get("tags") or [])]
        msg_lower = state.get("user_message", "").lower()
        
        # Normalizar action_tags a lista
        if isinstance(action_tags, str):
            action_tags = [action_tags]
        
        action_tags_lower = [str(t).lower() for t in action_tags]
        
        # Coincide si alg√∫n tag de la acci√≥n aparece en el mensaje o en los tags del usuario
        for tag in action_tags_lower:
            if tag in msg_lower or tag in user_tags:
                return True
        
        return False
    
    # Aplicar ambos filtros
    state["actions"] = {
        k: v for k, v in all_actions.items() 
        if area_matches(v) and has_relevant_tags(v)
    }
    
    print(f"\nüè¢ Compa√±√≠a: {company}")
    print(f"üìç √Årea: {area}")
    print(f"‚úÖ Acciones disponibles (filtradas por √°rea y tags): {list(state['actions'].keys())}\n")
        
    return state



def interpret_intent(state: OrchestratorState) -> OrchestratorState:
    """
    Interpreta la intenci√≥n del usuario usando Gemini.
    
    Args:
        state: Estado actual del orquestador
        
    Returns:
        Estado actualizado con la interpretaci√≥n
    """
    try:
        # Intentar interpretar la intenci√≥n
        state["interpretation"] = IntentEngine.interpret(
            state["user_message"],
            state["area"],
            state["actions"]
        )

    except Exception as e:
        # En caso de error (e.g. Gemini 503, 429), retornar acci√≥n 'none' 
        # pero guardando el error para debugging si es necesario
        print(f"‚ùå Error en interpret_intent: {e}")
        state["interpretation"] = {
            "action": "none", 
            "params": {},
            "_error": str(e)  # Guardar error para posible uso
        }
        
        # Opcional: Si queremos fallar fallar r√°pido y devolver error al usuario
        # descomentar lo siguiente:
        # state["result"] = {
        #     "status": False,
        #     "msg": f"No se pudo interpretar la intenci√≥n: {str(e)}",
        #     "data": {"opciones": list(state["actions"].keys())}
        # }
        # Esto requerir√≠a cambiar el flujo del grafo para ir directo a END
        
    return state


def execute_action(state: OrchestratorState) -> OrchestratorState:
    """
    Ejecuta la acci√≥n interpretada.
    
    Args:
        state: Estado actual del orquestador
        
    Returns:
        Estado actualizado con el resultado
    """
    interpretation = state["interpretation"]
    action_name = interpretation.get("action")
    params = interpretation.get("params", {})
    
    print(f"‚öôÔ∏è Ejecutando acci√≥n: {action_name} con params: {params}")
    
    # Obtener configuraci√≥n de la acci√≥n desde el estado combinado (default + company)
    action_config = state["actions"].get(action_name)

    # Soporte para tareas compuestas (tarea padre con subtareas/steps)
    if action_config and action_config.get("type") == "composite":
        steps = action_config.get("steps", []) or []
        results: Dict[str, Any] = {}
        
        for idx, step in enumerate(steps):
            step_id = step.get("id") or f"step_{idx+1}"
            step_action = step.get("action")
            if not step_action:
                state["result"] = {
                    "status": False,
                    "msg": f"El step '{step_id}' no define 'action'"
                }
                return state

            # Construir par√°metros del step: defaults del step, luego params espec√≠ficos del step,
            # y por √∫ltimo los params del parent (permitiendo override por el usuario)
            step_defaults = step.get("params", {}) or {}
            user_step_params = (state.get("interpretation", {}).get("params", {}).get(step_id, {})) if state.get("interpretation") else {}
            merged_params = {**step_defaults, **user_step_params, **params}

            # Validar requeridos contra el esquema del step_action
            missing = _missing_required_for(step_action, merged_params, state)
            if missing:
                state["result"] = {
                    "status": False,
                    "msg": f"Faltan par√°metros para la subtarea '{step_id}' ({step_action})",
                    "data": {
                        "step": step_id,
                        "action": step_action,
                        "missing": missing,
                        "required": state["actions"].get(step_action, {}).get("parameters", {}).get("required", [])
                    },
                    "followups": [
                        {
                            "question": f"¬øPuedes proporcionar {', '.join(missing)} para '{step_id}'?",
                            "step": step_id,
                            "action": step_action
                        }
                    ]
                }
                return state

            # Determinar handler del step
            step_config = state["actions"].get(step_action) or {}
            step_handler_name = step_config.get("handler") or step_config.get("class") or step_action

            # Preparar dependencias (reutilizamos la misma l√≥gica)
            dependencies = {
                "actions": state["actions"],
                "username": state["username"]
            }
            if step_handler_name == "jira" or step_action in ["epicas", "sprints"]:
                dependencies["jira_service"] = JiraService(None)
                if "jira_method" in step_config:
                    merged_params["_jira_method"] = step_config["jira_method"]

            handler = ActionFactory.create(step_handler_name, **dependencies)
            if not handler:
                state["result"] = {
                    "status": False,
                    "msg": f"Handler no encontrado para subtarea: {step_handler_name}"
                }
                return state

            # Identificar acci√≥n del step y ejecutar
            merged_params["_action"] = step_action
            step_result = handler.execute(merged_params)
            results[step_id] = step_result

            # Si un step falla, detener el flujo compuesto
            if not step_result.get("status", True):
                state["result"] = {
                    "status": False,
                    "msg": f"Fall√≥ la subtarea '{step_id}': {step_result.get('msg', 'Error en ejecuci√≥n')}",
                    "data": {"steps": results}
                }
                return state

        # Todas las subtareas OK
        state["result"] = {
            "status": True,
            "msg": f"Flujo compuesto '{action_name}' ejecutado correctamente",
            "data": {"steps": results}
        }
        return state
    
    if not action_config:
        state["result"] = {
            "status": False,
            "msg": f"Acci√≥n no reconocida en el sistema: {action_name}",
            "data": {
                "opciones": list(state["actions"].keys())
            }
        }
        return state
    
    # Determinar el handler a usar
    # Soporta tanto "handler" (estructura optimizada) como "class" (estructura actual)
    # Soportar tanto "handler" (preferido) como "class" (compatibilidad)
    handler_name = action_config.get("handler") or action_config.get("class") or action_name
    
    # Preparar dependencias seg√∫n el handler
    dependencies = {
        "actions": state["actions"],
        "username": state["username"]
    }
    
    # Si es una acci√≥n de Jira (por handler o por action_name)
    if handler_name == "jira" or action_name in ["epicas", "sprints"]:
        dependencies["jira_service"] = JiraService(None)
        
        # Agregar m√©todo de Jira si est√° especificado en Redis
        if "jira_method" in action_config:
            params["_jira_method"] = action_config["jira_method"]
    
    # Crear instancia del handler usando el factory
    handler = ActionFactory.create(handler_name, **dependencies)
    
    if not handler:
        state["result"] = {
            "status": False,
            "msg": f"Handler no encontrado para: {handler_name}"
        }
        return state
    
    # Agregar nombre de acci√≥n a los par√°metros
    params["_action"] = action_name
    
    # Ejecutar acci√≥n
    state["result"] = handler.execute(params)
    return state
